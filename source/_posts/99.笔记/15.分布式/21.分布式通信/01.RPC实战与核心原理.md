---
title: RPC实战与核心原理
date: 2022-06-19 09:48:17
categories:
  - 笔记
  - 分布式
  - 分布式通信
tags:
  - 分布式
  - 分布式通信
  - RPC
permalink: /pages/4b43b4/
---

# RPC 实战与核心原理

为什么要学习 RPC

RPC 不仅是微服务的架构基础，实际上，只要涉及网络通信，就可能用到 RPC。

例 1：大型分布式应用系统可能会依赖消息队列、分布式缓存、分布式数据库以及统一配置
中心等，应用程序与依赖的这些中间件之间都可以通过 RPC 进行通信。比如 etcd，它作为
一个统一的配置服务，客户端就是通过 gRPC 框架与服务端进行通信的。

例 2：我们经常会谈到的容器编排引擎 Kubernetes，它本身就是分布式的，Kubernetes
的 kube-apiserver 与整个分布式集群中的每个组件间的通讯，都是通过 gRPC 框架进行
的。

RPC 是解决分布式系统通信问题的一大利器。

## 核心原理

### 什么是 RPC？

RPC 的全称是 Remote Procedure Call，即远程过程调用。

RPC 的作用体现在两个方面：

- 屏蔽远程调用跟本地调用的差异，让用户像调用本地一样去调用远程方法。
- 隐藏底层网络通信的复杂性，让用户更专注于业务逻辑。

### RPC 通信流程

![](https://raw.githubusercontent.com/dunwu/images/dev/snap/20220619100051.png)

RPC 是一个远程调用，因此必然需要通过网络传输数据，且 RPC 常用于业务系统之间的数据交互，需要保证其可靠性，所以 RPC 一般默认采用 **TCP** 来传输。

网络传输数据是二进制数据，因此请求方需要将请求参数转为二进制数据，即**序列化**。

响应方接受到请求，要将二进制数据转换为请求参数，需要**反序列化**。

请求方和响应方识别彼此的信息，需要约定好彼此数据的格式，即**协议**。大多数的协议会分成两部分，分别是数据头和消息体。数据头一般用于身份识别，包括协议标识、数据大小、请求类型、序列化类型等信息；消息体主要是请求的业务参数信息和扩展属性等。

为了屏蔽底层通信细节，使用户聚焦自身业务，因此 RPC 框架一般引入了动态代理，通过依赖注入等技术，拦截方法调用，完成远程调用的通信逻辑。

### RPC 在架构中的位置

RPC 框架能够帮助我们解决系统拆分后的通信问题，并且能让我们像调用本地一样去调用
远程方法。

![](https://raw.githubusercontent.com/dunwu/images/dev/snap/20220619101023.png)

## 协议

### 协议的作用

在传输过程中，RPC 并不会把请求参数的所有二进制数据整体一下子发送到对端机器上，中间可能会拆分成好几个数据包，也可能会合并其他请求的数据包（合并的前提是同一个 TCP 连接上的数据），至于怎么拆分合并，这其中的细节会涉及到系统参数配置和 TCP 窗口大小。对于服务提供方应用来说，他会从 TCP 通道里面收到很多的二进制数据，那这时候怎么识别出哪些二进制是第一个请求的呢？

这就好比让你读一篇没有标点符号的文章，你要怎么识别出每一句话到哪里结束呢？很简单
啊，我们加上标点，完成断句就好了。

为了避免语义不一致的事情发生，我们就需要在发送请求的时候设定一个边界，然后在收到请求的时候按照这个设定的边界进行数据分割。这个边界语义的表达，就是我们所说的协议。

### 为何需要设计 RPC 协议

有了现成的 HTTP 协议，为啥不直接用，还要为 RPC 设计私有协议呢？

RPC 更多的是负责应用间的通信，所以性能要求相对更高。但 HTTP 协议的数据包大小相对请求数据本身要大很多，又需要加入很多无用的内容，比如换行符号、回车符等；还有一个更重要的原因是，HTTP 协议属于无状态协议，客户端无法对请求和响应进行关联，每次请求都需要重新建立连接，响应完成后再关闭连接。因此，对于要求高性能的 RPC 来说，HTTP 协议基本很难满足需求，所以 RPC 会选择设计更紧凑的私有协议。

### 如何设计 RPC 协议？

首先，必须先明确消息的边界，即确定消息的长度。因此，至少要分为：消息长度+消息内容两部分。

接下来，我们会发现，在使用过程中，仅消息长度，不足以明确通信中的很多细节：如序列化方式是怎样的？是否消息压缩？压缩格式是怎样的？如果协议发生变化，需要明确协议版本等等。

综上，一个 RPC 协议大概会由下图中的这些参数组成：

![](https://raw.githubusercontent.com/dunwu/images/dev/snap/20220619102052.png)

### 可扩展的协议

前面所述的协议属于定长协议头，那也就是说往后就不能再往协议头里加新参数了，如果加参
数就会导致线上兼容问题。

为了保证能平滑地升级改造前后的协议，我们有必要设计一种支持可扩展的协议。其关键在于让协议头支持可扩展，扩展后协议头的长度就不能定长了。那要实现读取不定长的协议头里面的内容，在这之前肯定需要一个固定的地方读取长度，所以我们需要一个固定的写入协议头的长度。整体协议就变成了三部分内容：固定部分、协议头内容、协议体内容。

![](https://raw.githubusercontent.com/dunwu/images/dev/snap/20220619102833.png)

## 序列化

在不同的场景下合理地选择序列化方式，对提升 RPC 框架整体的稳定性和性能是至关重要的。

![](https://raw.githubusercontent.com/dunwu/images/dev/snap/20220619101617.png)

序列化就是将对象转换成二进制数据的过程，而反序列就是反过来将二进制转换为对象的过程。

![](https://raw.githubusercontent.com/dunwu/images/dev/snap/20220619104420.png)

常用序列化方式

- JDK 序列化：`ObjectInputStream` 和 `ObjectOutputStream`
- JSON
- 二进制
  - Hessian
  - Protobuf
  - Thirft

**RPC 协议选型**

优先级依次从高到低：安全性、通用性、兼容性、性能、效率、空间开销。

这归根结底还是因为服务调用的稳定性与可靠性，要比服务的性能与响应耗时更加重要。另
外对于 RPC 调用来说，整体调用上，最为耗时、最消耗性能的操作大多都是服务提供者执
行业务逻辑的操作，这时序列化的开销对于服务整体的开销来说影响相对较小。

**使用 RPC 需要注意哪些问题**

1. 对象要尽量简单，没有太多的依赖关系，属性不要太多，尽量高内聚；
2. 入参对象与返回值对象体积不要太大，更不要传太大的集合；
3. 尽量使用简单的、常用的、开发语言原生的对象，尤其是集合类；
4. 对象不要有复杂的继承关系，最好不要有父子类的情况。

## 网络通信

常见的网络 IO 模型分为四种：同步阻塞 IO（BIO）、同步非阻塞 IO（NIO）、IO 多路复
用和异步非阻塞 IO（AIO）。在这四种 IO 模型中，只有 AIO 为异步 IO，其他都是同步
IO。

IO 多路复用（Reactor 模式）在高并发场景下使用最为广泛，很多知名软件都应用了这一技术，如：Netty、Redis、Nginx 等。

IO 多路复用分为 select，poll 和 epoll。

什么是 IO 多路复用？字面上的理解，多路就是指多个通道，也就是多个网络连接的 IO，而复用就是指多个通道复用在一个复用器上。

### 零拷贝

系统内核处理 IO 操作分为两个阶段——等待数据和拷贝数据。等待数据，就是系统内核在等待网卡接收到数据后，把数据写到内核中；而拷贝数据，就是系统内核在获取到数据后，将数据拷贝到用户进程的空间中。

网络 IO 读写流程

![](https://raw.githubusercontent.com/dunwu/images/dev/snap/20220619174154.png)

应用进程的每一次写操作，都会把数据写到用户空间的缓冲区中，再由 CPU 将数据拷贝到系统内核的缓冲区中，之后再由 DMA 将这份数据拷贝到网卡中，最后由网卡发送出去。这里我们可以看到，一次写操作数据要拷贝两次才能通过网卡发送出去，而用户进程的读操作则是将整个流程反过来，数据同样会拷贝两次才能让应用程序读取到数据。

应用进程的一次完整的读写操作，都需要在用户空间与内核空间中来回拷贝，并且每一次拷贝，都需要 CPU 进行一次上下文切换（由用户进程切换到系统内核，或由系统内核切换到用户进程），这样很浪费 CPU 和性能。

所谓的零拷贝，就是取消用户空间与内核空间之间的数据拷贝操作，应用进程每一次的读写操作，可以通过一种方式，直接将数据写入内核或从内核中读取数据，再通过 DMA 将内核中的数据拷贝到网卡，或将网卡中的数据 copy 到内核。

![](https://raw.githubusercontent.com/dunwu/images/dev/snap/20220619174335.png)

Netty 的零拷贝偏向于用户空间中对数据操作的优化，这对处理 TCP 传输中的拆包粘包问题有着重要的意义，对应用程序处理请求数据与返回数据也有重要的意义。

Netty 框架中很多内部的 ChannelHandler 实现类，都是通过 CompositeByteBuf、slice、wrap 操作来处理 TCP 传输中的拆包与粘包问题的。

Netty 的 ByteBuffer 可以采用 Direct Buffers，使用堆外直接内存进行 Socketd 的读写
操作，最终的效果与我刚才讲解的虚拟内存所实现的效果是一样的。

Netty 还提供 FileRegion 中包装 NIO 的 FileChannel.transferTo() 方法实现了零拷
贝，这与 Linux 中的 sendfile 方式在原理上也是一样的。

## 动态代理

动态代理可以帮用户屏蔽远程调用的细节，实现像调用本地一样地调用远程的体验。

![](https://raw.githubusercontent.com/dunwu/images/dev/snap/20220619204255.png)

JDK 支持的动态代理方式是通过实现 InvocationHandler 接口。这种方式有一定的局限性——它要求被代理的类只能是接口。原因是因为生成的代理类会继承 Proxy 类，但 Java 是不支持多重继承的。此外，它还有性能问题。它生成后的代理类是使用反射来完成方法调用的，而这种方式相对直接用编码调用来说，性能会降低。

除 JDK 以外，还有其他第三方框架可以实现动态代理，如像 Javassist、Byte Buddy。

Javassist 的是通过控制底层字节码来实现动态代理，不需要反射完成调用，所以性能肯定比 JDK 的动态代理方式性能要好。

Byte Buddy 则属于后起之秀，在很多优秀的项目中，像 Spring、Jackson 都用到了 Byte Buddy 来完成底层代理。相比 Javassist，Byte Buddy 提供了更容易操作的 API，编写的代码可读性更高。更重要的是，生成的代理类执行速度比 Javassist 更快。

## RPC 实战

## 架构设计

## 服务发现

## 健康检测

## 路由策略

## 负载均衡

## 异常重试

## 优雅关闭

## 优雅启动

## 熔断限流

## 业务分组

## 异步 RPC

## 安全体系

## 问题定位

## 时钟轮

## 流量回放

## 动态分组
